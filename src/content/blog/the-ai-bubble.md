---
title: "The AI Bubble: We’re Building Cathedrals for a Religion That Doesn't Exist Yet"
description: "The AI hype is cooling, but let’s be clear: it isn’t dying. It’s just hitting a wall of reality. An opinion piece on the current state of AI investment."
pubDate: 2026-02-09
tags: ["AI", "Technology", "Opinion", "Market"]
---

The AI hype is cooling, but let’s be clear: it isn’t dying. It’s just hitting a wall of reality.
What’s likely to burst isn’t the technology itself, but the delusional expectation that Artificial General Intelligence (AGI) is right around the corner. I’ll say it plainly: I don’t think it is. In fact, I don’t think we’re even close. But the market has already priced AGI into the soul of the global economy, and when that bill comes due, it’s going to hurt everyone whether you use ChatGPT or not.
To understand where we are, we have to look back at the "pipes."

## The Ghost of Fiber Optics Past

During the dot-com boom, the world was convinced internet traffic would grow infinitely and immediately. The mantra was simple: whoever owns the pipes controls the future.
Trillions of dollars poured into fiber-optic infrastructure. Millions of kilometers of fiber were laid, wiring entire continents multiple times over. By 2001, reality checked in: only 5% to 10% of that fiber was actually being used. The rest sat as "dark fiber" billions of dollars of glass buried in the dirt, doing nothing.

The fallout was catastrophic:
*   **Massive Bankruptcies:** Telecom giants vanished overnight.
*   **Job Losses:** Over two million people were laid off.
*   **Pension Collapse:** Retirement accounts were devastated, with some losing 80% of their value.

Was the internet a mistake? Of course not. It changed the world. But that overbuilt infrastructure didn't become truly "useful" until 15 years later. We built the stadium before we even knew how to play the game.

## History Doesn't Repeat, But It Rhymes

We are seeing the exact same pattern with AI infrastructure. We are vastly overestimating the near-term value of AI while the technology is only improving marginally compared to the vertical climb of the hype.
Today, AI spending is effectively propping up a massive chunk of US GDP growth. But what happens when the "AGI isn't coming" realization sets in?

*   **A Deeper Crash:** I expect the fallout to be worse than 2001. More capital will vanish, and many AI startups will be liquidated, leaving only the "Too Big To Fail" players like Google standing.
*   **Fire Sales:** Just as fiber-optic installation dropped from $1,000 per meter to $10, today’s high-end compute power will eventually sell for pennies on the dollar.
*   **The Great Stagnation:** AI development will stop being aggressively shoved into every toaster and toothbrush. Prices will fall, but so will innovation.

## The "National Security" Bailout

My main concern? The industry knows this is coming. They see the cliff, and they’re hitting the accelerator anyway.
There seems to be a cynical assumption that when the bubble pops, governments will step in and bail out the industry by framing AI as a "national security necessity." If that happens, it’ll be the final nail in the coffin for grassroots innovation and startups. We’ll be left with a government-subsidized oligarchy of AI giants.

## The Coming Winter

History shows that crashes are followed by "funding winters." We saw it in 2001, 2008, and even in the 1980s during the first major AI winter. Back then, the hype was around "Expert Systems." When they failed to deliver, research budgets were slashed so hard that scientists stopped using the term "AI" entirely just to keep their jobs.
AI winters don’t happen because the tech is "fake." They happen because expectations ran faster than the code.

## The Transformer Ceiling

Unless there is a fundamental breakthrough a "Newtonian" moment for AI, I don’t think we’ll ever achieve AGI with our current path.
Transformer models are hitting a ceiling. Sure, we’ll continue to get better model and develop tools that take more advantage of our AI systems, but at the end of the day, they are still fundamentally predictive engines. They are mirrors, not minds. We’ve already seen how limited that makes them in truly creative or autonomous processes.

We are currently building the most expensive infrastructure in human history for a breakthrough that's decades away - if it arrives at all. The question isn't whether AI is useful, it's whether we are fundamentally heading in the wrong direction.
